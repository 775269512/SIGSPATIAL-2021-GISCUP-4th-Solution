{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad341fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from IPython.core.debugger import set_trace\n",
    "import re\n",
    "import ujson\n",
    "import pickle\n",
    "import msgpack\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "import yaml\n",
    "\n",
    "from common_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1317f63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = yaml.safe_load(open('./config.yml').read())\n",
    "\n",
    "data_dir = Path(paths['data_dir'])\n",
    "pkl_dir = Path(paths['pkl_dir'])\n",
    "msg_dir = Path(paths['msg_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f95114b",
   "metadata": {},
   "source": [
    "## weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a723d19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv(data_dir/'weather.csv')\n",
    "\n",
    "# Monday is indexed as 0 and Sunday is 6\n",
    "def lamb(x):\n",
    "    # int 20200801 to weekday\n",
    "    x = str(x)\n",
    "    dt = datetime(year=int(x[0:4]), \n",
    "                  month=int(x[4:6]), \n",
    "                  day=int(x[6:8]))\n",
    "    return dt.weekday()\n",
    "\n",
    "weather['weekday'] = weather.date.apply(lambda x: lamb(x))\n",
    "weather['weather_code'] = pd.Categorical(weather.weather).codes\n",
    "weather = weather.set_index(\"date\")\n",
    "weather = weather[[\"lowtemp\", \"hightemp\", \"weekday\", \"weather_code\"]]\n",
    "\n",
    "weather_dct = {}\n",
    "for item in weather.iterrows():\n",
    "    weather_dct[str(item[0])] = item[1]\n",
    "\n",
    "dump_pickle(weather_dct, pkl_dir/'weather_dct.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcfb04c",
   "metadata": {},
   "source": [
    "## all lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7646780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38d1afea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 20200801.txt\n",
      "loading 20200802.txt\n",
      "loading 20200901_test.txt\n"
     ]
    }
   ],
   "source": [
    "lines_dct = {}\n",
    "\n",
    "# train lines\n",
    "for i in range(1, end_date+1):\n",
    "    print(f\"loading 202008{i:02d}.txt\")\n",
    "    try:\n",
    "        with open(data_dir/f'train/202008{i:02d}.txt', 'r') as f:\n",
    "            lines_dct[f'202008{i:02d}'] = f.readlines()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"not found 202008{i:02d}.txt\")\n",
    "        pass\n",
    "\n",
    "# test lines\n",
    "with open(data_dir/f'20200901_test.txt', 'r') as f:\n",
    "    print(f\"loading 20200901_test.txt\")\n",
    "    lines_dct['20200901'] = f.readlines()\n",
    "\n",
    "dump_pickle(lines_dct, pkl_dir/\"lines_dct.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3483234a",
   "metadata": {},
   "source": [
    "## link_freq_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48304005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 318 ms, sys: 669 ms, total: 987 ms\n",
      "Wall time: 985 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lines_dct = load_pickle(pkl_dir/'lines_dct.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06443396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line2link(line):\n",
    "    return [ll.split(':')[0] for ll in line.split(';;')[1].split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d164078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f859ce8338994cfa87ae31aeaff6a0f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "247fadd5cf674c66b832d5ced481a304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38aca779dc1c4b6488c112c6d218a3a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/288076 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_links = []\n",
    "for k, lines in lines_dct.items():\n",
    "    for line in tqdm(lines):\n",
    "         all_links += line2link(line)\n",
    "dump_pickle(Counter(all_links), pkl_dir/'link_freq.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a1f353",
   "metadata": {},
   "source": [
    "## driver pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a200e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line2head(line):\n",
    "    return line.split(';')[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c4d4a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "for k, v in lines_dct.items():\n",
    "    lines += v\n",
    "\n",
    "all_drivers = list(set([ line2head(line)[-2] for line in lines]))\n",
    "\n",
    "driver_dct = dict()\n",
    "\n",
    "for idx, driver in enumerate(all_drivers):\n",
    "    driver_dct[int(driver)] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f3e52ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_pickle(driver_dct, pkl_dir/\"driver2id_dct.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f32121",
   "metadata": {},
   "source": [
    "## create train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68eaccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines(path):\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        return lines\n",
    "    \n",
    "def line2part(line):\n",
    "    head, link, cross = line.split(';;')\n",
    "    return head, link, cross  \n",
    "\n",
    "def link2npary(link):\n",
    "    return np.asarray(\n",
    "            [re.split(':|,', l) for l in link.split()], \n",
    "             dtype=float\n",
    "           )\n",
    "def cross2npary(cross):\n",
    "    return np.asarray([ re.split('_|:', c) for c in cross.split()], dtype='float')\n",
    "\n",
    "def line2dict(line, weather):\n",
    "    weather_keys = [\"lowtemp\", \"hightemp\", \"weekday\", \"weather\"]\n",
    "    lowtemp = weather['lowtemp'].tolist()\n",
    "    hightemp = weather['hightemp'].tolist()\n",
    "    weekday = weather['weekday'].tolist()\n",
    "    weather_code = weather['weather_code'].tolist()\n",
    "    \n",
    "    weather_dict = dict(zip(weather_keys, \n",
    "                            [lowtemp, hightemp, weekday, weather_code]\n",
    "                           )\n",
    "                       )\n",
    "    \n",
    "    head, link, cross = line2part(line)\n",
    "    \n",
    "    # head\n",
    "    head_keys = [\"order_id\", \"eta\", \"dist\", \"simple_eta\", \"driver_id\", \"slice_id\"]\n",
    "    head_dict = dict(zip(head_keys, np.asarray(head.split(), dtype=float)))\n",
    "    \n",
    "    # line\n",
    "    link_ary = link2npary(link)\n",
    "    link_id = link_ary[:, 0].tolist()\n",
    "\n",
    "    link_time = link_ary[:, 1].tolist()\n",
    "\n",
    "    link_ratio = link_ary[:, 2].tolist()\n",
    "\n",
    "    link_current_status = link_ary[:, 3].tolist()\n",
    "\n",
    "    link_arrival_status = link_ary[:, 4].tolist()\n",
    "\n",
    "    link_keys = [\"link_id\", \"link_time\", \"link_ratio\", \"link_current_status\", \"link_arrival_status\"]\n",
    "\n",
    "    link_dict = dict(zip(link_keys, \n",
    "             [link_id, link_time, link_ratio, link_current_status, link_arrival_status]))\n",
    "    \n",
    "\n",
    "    # cross\n",
    "    if len(cross.strip()) == 0:\n",
    "        cross_start = []\n",
    "        cross_end = []\n",
    "        cross_time = []\n",
    "        \n",
    "        cross_keys = [\"cross_start\", \"cross_end\", \"cross_time\"]\n",
    "        cross_dict = dict(zip(cross_keys, \n",
    "                 [cross_start, cross_end, cross_time]))\n",
    "    else:\n",
    "        cross_ary = cross2npary(cross)\n",
    "\n",
    "        cross_start = cross_ary[:, 0].tolist()\n",
    "        cross_end = cross_ary[:, 1].tolist()\n",
    "        cross_time = cross_ary[:, 2].tolist()\n",
    "\n",
    "        cross_keys = [\"cross_start\", \"cross_end\", \"cross_time\"]\n",
    "        cross_dict = dict(zip(cross_keys, \n",
    "                 [cross_start, cross_end, cross_time]))\n",
    "    \n",
    "    # combine all    \n",
    "    line_dict = {}\n",
    "    \n",
    "    line_dict.update(head_dict)\n",
    "    line_dict.update(link_dict)\n",
    "    line_dict.update(cross_dict)\n",
    "    line_dict.update(weather_dict)\n",
    "    \n",
    "    return line_dict\n",
    "\n",
    "def raw2msgpack(path, day_weather, num_workers=40):\n",
    "    \"输入要处理的文件路径\"\n",
    "    lines = get_lines(path)\n",
    "\n",
    "    pool = ProcessPoolExecutor(max_workers=num_workers)\n",
    "    \n",
    "    line2dict_weather = partial(line2dict, weather=day_weather)\n",
    "\n",
    "    lines_dict = list(pool.map(line2dict_weather, lines))\n",
    "    \n",
    "    stem = path.name.split('.')[0]\n",
    "    \n",
    "    msg_path = Path(msg_dir/f'{stem}.msgpack')\n",
    "    msg_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with open(msg_path, 'wb') as f:\n",
    "        packed = msgpack.packb(lines_dict)\n",
    "        f.write(packed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec037deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20200801.txt\n",
      "Processing 20200802.txt\n"
     ]
    }
   ],
   "source": [
    "# generate all train data\n",
    "for i in range(1, end_date+1):\n",
    "    \n",
    "    file_name = f\"202008{i:02}.txt\"\n",
    "    print(f\"Processing {file_name}\")\n",
    "\n",
    "    day_weather = weather_dct[f'202008{i:02}']\n",
    "\n",
    "    raw2msgpack(data_dir/f'train/{file_name}', day_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e24b5b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate test data\n",
    "file_name = \"20200901_test.txt\"\n",
    "\n",
    "day_weather = weather_dct[f'20200901']\n",
    "\n",
    "raw2msgpack(data_dir/f'{file_name}', day_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e62b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
